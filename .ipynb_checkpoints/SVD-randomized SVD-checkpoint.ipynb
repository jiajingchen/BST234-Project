{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 50)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import fbpca \n",
    "\n",
    "\n",
    "def prep_data():\n",
    "    x = np.loadtxt(\"simulated_genos\", delimiter=\" \", dtype=\"float32\")\n",
    "    y = np.array([[1] * 10000 + [0] * 10000], dtype=\"float32\")\n",
    "    y_c = y - 0.5\n",
    "    return x, y_c\n",
    "\n",
    "x, y_c = prep_data()\n",
    "print (x.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 53.8 ms, sys: 20.3 ms, total: 74 ms\n",
      "Wall time: 102 ms\n",
      "[ 40.00001144  38.08315277  37.10234833  37.06640244  37.00000763\n",
      "  33.04753876  31.16459846  29.1289978   29.07105446  29.03992844\n",
      "  28.99998474  28.00000381  27.65703964  26.03939819  25.52819252\n",
      "  25.03122902  25.00000572  24.00005341  23.99998283  22.00000954\n",
      "  21.93363762  21.00001335  20.68578529  20.00000572  20.00000572\n",
      "  19.80418396  17.82784653  16.94734573  16.          15.99999428\n",
      "  14.92892456  13.00000191  11.99999332  11.95249748  11.00000381\n",
      "  10.99999619  10.00000668  10.00000286  10.           9.00000286\n",
      "   7.99999857   7.00000095   7.00000095   6.99999952   6.00000286   5.           4.\n",
      "   4.           3.96006298   1.        ]\n"
     ]
    }
   ],
   "source": [
    "# fbpca\n",
    "\n",
    "%time sig_rsvd_fbpca = fbpca.pca(x,50,True)[1]\n",
    "eig_rsvd_fbpca = sig_rsvd_fbpca ** 2\n",
    "print (eig_rsvd_fbpca)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 104 ms, sys: 31.1 ms, total: 136 ms\n",
      "Wall time: 95.7 ms\n",
      "[ 40.00001144  38.08315277  37.10234833  37.06640244  37.00000763\n",
      "  33.04753876  31.16459846  29.1289978   29.07105446  29.03992844\n",
      "  28.99998474  28.00000381  27.65703964  26.03939819  25.52819252\n",
      "  25.03122902  25.00000572  24.00005341  23.99998283  22.00000954\n",
      "  21.93363762  21.00001335  20.68578529  20.00000572  20.00000572\n",
      "  19.80418396  17.82784653  16.94734573  16.          15.99999428\n",
      "  14.92892456  13.00000191  11.99999332  11.95249748  11.00000381\n",
      "  10.99999619  10.00000668  10.00000286  10.           9.00000286\n",
      "   7.99999857   7.00000095   7.00000095   6.99999952   6.00000286   5.           4.\n",
      "   4.           3.96006298   1.        ]\n"
     ]
    }
   ],
   "source": [
    "#randomized SVD\n",
    "def randomized_svd(M, k=10):\n",
    "    m, n = M.shape\n",
    "    transpose = False\n",
    "    if m < n:\n",
    "        transpose = True\n",
    "        M = M.T\n",
    "        \n",
    "    rand_matrix = np.random.normal(size=(M.shape[1], k))  # short side by k\n",
    "    Q, _ = np.linalg.qr(M @ rand_matrix, mode='reduced')  # long side by k\n",
    "    smaller_matrix = Q.T @ M                              # k by short side\n",
    "    U_hat, s, V = np.linalg.svd(smaller_matrix, full_matrices=False)\n",
    "    U = Q @ U_hat\n",
    "    \n",
    "    if transpose:\n",
    "        return V.T, s.T, U.T\n",
    "    else:\n",
    "        return U, s, V\n",
    "    \n",
    "%time sig_rsvd = randomized_svd(x,50)[1]\n",
    "eig_rsvd = sig_rsvd_fbpca ** 2\n",
    "print (eig_rsvd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 212 ms, sys: 5.1 ms, total: 217 ms\n",
      "Wall time: 132 ms\n",
      "[40.000008, 38.083118, 37.102318, 37.066357, 37.0, 33.047501, 31.164595, 29.128979, 29.071066, 29.039942, 29.000004, 27.999998, 27.657055, 26.039402, 25.528193, 25.031223, 24.999998, 24.000011, 24.000008, 21.999998, 21.933632, 21.000002, 20.685776, 20.000002, 20.000002, 19.804171, 17.82782, 16.947344, 16.000002, 15.999995, 14.928931, 12.999998, 12.000002, 11.952483, 11.000003, 10.999998, 10.000003, 10.000002, 10.000001, 9.0000029, 7.9999995, 7.0000086, 7.000001, 6.999999, 6.0, 4.9999971, 4.0000086, 4.0000014, 3.9600585, 0.99998844]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#exact:\n",
    "from scipy import sparse\n",
    "import scipy.sparse.linalg as lg\n",
    "X_sparse = sparse.csr_matrix(x)\n",
    "X_T_sparse = sparse.csr_matrix.transpose(X_sparse)\n",
    "XX = X_sparse@X_T_sparse\n",
    "%time eig_exact = lg.eigsh(XX,k=50)\n",
    "eig_exact = sorted(eig_exact[0],reverse = True)\n",
    "print (eig_exact)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total error: \n",
      "0.000505328178406\n",
      "average error:\n",
      "1.01065635681e-05\n"
     ]
    }
   ],
   "source": [
    "# compare approximate methods to exact method's eigen\n",
    "eig_rsvd = list(eig_rsvd)\n",
    "\n",
    "total_error = 0\n",
    "for i in range(len(eig_rsvd)):\n",
    "    error = abs(eig_rsvd[i]-eig_exact[i])\n",
    "    total_error += error\n",
    "mean_error = total_error/len(eig_rsvd)\n",
    "print (\"total error: \")\n",
    "print (total_error)\n",
    "print (\"average error:\")\n",
    "print (mean_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  4.22249717e+00   2.36349245e-06   1.88150923e-02   3.46696356e-01\n",
      "   2.93465353e-01   1.88326688e-03   3.27403792e+00   3.39064589e+00\n",
      "   1.78429195e-01   7.81440684e+00   7.72462700e-01   9.42546572e-02\n",
      "   1.32419908e+00   7.59250096e-01   8.90931826e-02   6.21081165e-01\n",
      "   6.59404520e-02   1.62965874e-02   1.02554969e+00   6.73611319e-01\n",
      "   1.64165820e+00   3.93295878e-01   9.24367905e-01   9.59083983e-01\n",
      "   7.02447018e-01   9.18363540e-01   2.75252286e-01   3.34081424e+00\n",
      "   7.03181333e-01   1.30144469e+00   2.87427555e+00   1.28563029e+00\n",
      "   6.30204064e-01   5.27280472e-01   3.56839302e+00   2.77388644e-02\n",
      "   7.48344624e-02   2.80350556e+00   8.94497358e-02   1.13211872e+00\n",
      "   2.66240291e+00   1.42025669e-01   7.75088715e-01   6.92209220e-02\n",
      "   1.94455826e+00   3.70972545e-01   6.42047434e-02   7.66754579e-01\n",
      "   1.10107053e-01   4.92918697e+00   2.59498226e+00   1.20933201e+00\n",
      "   3.57518485e-01   1.22638618e+00   1.70675591e-01   7.90256661e-01\n",
      "   1.93328478e+00   1.93227393e+00   3.44821563e-02   4.45063085e-03\n",
      "   1.32359795e-01   1.66865021e-01   1.06485257e+00   3.01875724e-03\n",
      "   4.01568102e-02   3.17784249e+00   9.46821034e-02   2.26446581e-01\n",
      "   3.08817225e-02   7.19771078e-01   1.07205368e-01   2.95815163e-01\n",
      "   3.06969364e+00   1.10447419e-01   1.87741893e+00   1.66212592e-02\n",
      "   8.43117433e-02   2.35537428e-01   8.87517094e-01   4.76117514e-01\n",
      "   9.53946080e-02   4.70628213e-01   1.49615844e-01   2.97071579e-01\n",
      "   1.33118558e-02   5.96322603e-02   2.42422101e-01   9.02530361e-01\n",
      "   5.96238221e-01   2.92819009e-01   1.34501046e-01   6.55797242e-01\n",
      "   6.07449457e-02   8.68268571e-01   8.72737128e-01   1.07272239e-03\n",
      "   1.80934591e+00   1.88126460e-01   2.50846538e+00   4.63694868e+00]\n"
     ]
    }
   ],
   "source": [
    "# Monte Carlo, simulate the distribution of Q\n",
    "\n",
    "#generate chi-square r.v\n",
    "N = 100\n",
    "df = 1\n",
    "\n",
    "chisq_list = np.random.chisquare(df, size=N)\n",
    "print (chisq_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Process behind Randomized SVD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Here is a process to calculate a truncated SVD, described in [Finding Structure with Randomness: Probabilistic Algorithms for Constructing Approximate Matrix Decompositions](https://arxiv.org/pdf/0909.4061.pdf) and [summarized in this blog post](https://research.fb.com/fast-randomized-svd/):\n",
    "\n",
    "1\\. Compute an approximation to the range of $A$. That is, we want $Q$ with $r$ orthonormal columns such that $$A \\approx QQ^TA$$\n",
    "\n",
    "\n",
    "2\\. Construct $B = Q^T A$, which is small ($r\\times n$)\n",
    "\n",
    "\n",
    "3\\. Compute the SVD of $B$ by standard methods (fast since $B$ is smaller than $A$), $B = S\\,\\Sigma V^T$\n",
    "\n",
    "4\\. Since $$ A \\approx Q Q^T A = Q (S\\,\\Sigma V^T)$$ if we set $U = QS$, then we have a low rank approximation $A \\approx U \\Sigma V^T$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### So how do we find $Q$ (in step 1)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To estimate the range of $A$, we can just take a bunch of random vectors $w_i$, evaluate the subspace formed by $Aw_i$.  We can form a matrix $W$ with the $w_i$ as it's columns.  Now, we take the QR decomposition of $AW = QR$, then the columns of $Q$ form an orthonormal basis for $AW$, which is the range of $A$.\n",
    "\n",
    "Since the matrix $AW$ of the product has far more rows than columns and therefore, approximately, orthonormal columns. This is simple probability - with lots of rows, and few columns, it's unlikely that the columns are linearly dependent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Why M ~ Q Q.T M"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are trying to find a matrix Q such that $M \\approx Q Q^T M$.  We are interested in the range of $M$, let's call this $MX$.  $Q$ has orthonormal columns so $Q^TQ = I$ (but $QQ^T$ isn't $I$, since $Q$ is rectangular)\n",
    "\n",
    "$$ QR = MX $$\n",
    "$$ QQ^TQR = QQ^TMX $$\n",
    "$$ QR = QQ^TMX $$\n",
    "so...\n",
    "$$ MX = QQ^TMX $$\n",
    "\n",
    "If $X$ is the identity, we'd be done (but then $X$ would be too big, and we wouldn't get the speed up we're looking for).  In our problem, $X$ is just a small random matrix.  The Johnson-Lindenstrauss Lemma provides some justification of why this works."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The QR Decomposition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be learning about the QR decomposition **in depth** later on.  For now, you just need to know that $A = QR$, where $Q$ consists of orthonormal columns, and $R$ is upper triangular.  Trefethen says that the QR decomposition is the most important idea in numerical linear algebra!  We will definitely be returning to it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How should we choose $r$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose our matrix has 100 columns, and we want 5 columns in U and V. To be safe, we should project our matrix onto an orthogonal basis with a few more rows and columns than 5 (let's use 15).  At the end, we will just grab the first 5 columns of U and V\n",
    "\n",
    "So even although our projection was only approximate, by making it a bit bigger than we need, we can make up for the loss of accuracy (since we're only taking a subset later). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

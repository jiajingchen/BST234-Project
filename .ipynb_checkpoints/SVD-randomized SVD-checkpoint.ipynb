{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 50)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import fbpca \n",
    "\n",
    "\n",
    "def prep_data():\n",
    "    x = np.loadtxt(\"simulated_genos\", delimiter=\" \", dtype=\"float32\")\n",
    "    y = np.array([[1] * 10000 + [0] * 10000], dtype=\"float32\")\n",
    "    y_c = y - 0.5\n",
    "    return x, y_c\n",
    "\n",
    "x, y_c = prep_data()\n",
    "print (x.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 26.3 ms, sys: 2.3 ms, total: 28.6 ms\n",
      "Wall time: 18.4 ms\n",
      "[ 40.00001144  38.08315277  37.10234833  37.06640244  37.00000763\n",
      "  33.04753876  31.16459846  29.1289978   29.07105446  29.03992844\n",
      "  28.99998474  28.00000381  27.65703964  26.03939819  25.52819252\n",
      "  25.03122902  25.00000572  24.00005341  23.99998283  22.00000954\n",
      "  21.93363762  21.00001335  20.68578529  20.00000572  20.00000572\n",
      "  19.80418396  17.82784653  16.94734573  16.          15.99999428\n",
      "  14.92892456  13.00000191  11.99999332  11.95249748  11.00000381\n",
      "  10.99999619  10.00000668  10.00000286  10.           9.00000286\n",
      "   7.99999857   7.00000095   7.00000095   6.99999952   6.00000286   5.           4.\n",
      "   4.           3.96006298   1.        ]\n"
     ]
    }
   ],
   "source": [
    "# fbpca\n",
    "\n",
    "%time sig_rsvd_fbpca = fbpca.pca(x,50,True)[1]\n",
    "eig_rsvd_fbpca = sig_rsvd_fbpca ** 2\n",
    "print (eig_rsvd_fbpca)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 99.9 ms, sys: 18.4 ms, total: 118 ms\n",
      "Wall time: 76 ms\n",
      "[ 40.00001144  38.08315277  37.10234833  37.06640244  37.00000763\n",
      "  33.04753876  31.16459846  29.1289978   29.07105446  29.03992844\n",
      "  28.99998474  28.00000381  27.65703964  26.03939819  25.52819252\n",
      "  25.03122902  25.00000572  24.00005341  23.99998283  22.00000954\n",
      "  21.93363762  21.00001335  20.68578529  20.00000572  20.00000572\n",
      "  19.80418396  17.82784653  16.94734573  16.          15.99999428\n",
      "  14.92892456  13.00000191  11.99999332  11.95249748  11.00000381\n",
      "  10.99999619  10.00000668  10.00000286  10.           9.00000286\n",
      "   7.99999857   7.00000095   7.00000095   6.99999952   6.00000286   5.           4.\n",
      "   4.           3.96006298   1.        ]\n"
     ]
    }
   ],
   "source": [
    "#randomized SVD\n",
    "def randomized_svd(M, k=10):\n",
    "    m, n = M.shape\n",
    "    transpose = False\n",
    "    if m < n:\n",
    "        transpose = True\n",
    "        M = M.T\n",
    "        \n",
    "    rand_matrix = np.random.normal(size=(M.shape[1], k))  # short side by k\n",
    "    Q, _ = np.linalg.qr(M @ rand_matrix, mode='reduced')  # long side by k\n",
    "    smaller_matrix = Q.T @ M                              # k by short side\n",
    "    U_hat, s, V = np.linalg.svd(smaller_matrix, full_matrices=False)\n",
    "    U = Q @ U_hat\n",
    "    \n",
    "    if transpose:\n",
    "        return V.T, s.T, U.T\n",
    "    else:\n",
    "        return U, s, V\n",
    "    \n",
    "%time sig_rsvd = randomized_svd(x,50)[1]\n",
    "eig_rsvd = sig_rsvd_fbpca ** 2\n",
    "print (eig_rsvd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Process behind Randomized SVD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Here is a process to calculate a truncated SVD, described in [Finding Structure with Randomness: Probabilistic Algorithms for Constructing Approximate Matrix Decompositions](https://arxiv.org/pdf/0909.4061.pdf) and [summarized in this blog post](https://research.fb.com/fast-randomized-svd/):\n",
    "\n",
    "1\\. Compute an approximation to the range of $A$. That is, we want $Q$ with $r$ orthonormal columns such that $$A \\approx QQ^TA$$\n",
    "\n",
    "\n",
    "2\\. Construct $B = Q^T A$, which is small ($r\\times n$)\n",
    "\n",
    "\n",
    "3\\. Compute the SVD of $B$ by standard methods (fast since $B$ is smaller than $A$), $B = S\\,\\Sigma V^T$\n",
    "\n",
    "4\\. Since $$ A \\approx Q Q^T A = Q (S\\,\\Sigma V^T)$$ if we set $U = QS$, then we have a low rank approximation $A \\approx U \\Sigma V^T$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### So how do we find $Q$ (in step 1)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To estimate the range of $A$, we can just take a bunch of random vectors $w_i$, evaluate the subspace formed by $Aw_i$.  We can form a matrix $W$ with the $w_i$ as it's columns.  Now, we take the QR decomposition of $AW = QR$, then the columns of $Q$ form an orthonormal basis for $AW$, which is the range of $A$.\n",
    "\n",
    "Since the matrix $AW$ of the product has far more rows than columns and therefore, approximately, orthonormal columns. This is simple probability - with lots of rows, and few columns, it's unlikely that the columns are linearly dependent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Why M ~ Q Q.T M"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are trying to find a matrix Q such that $M \\approx Q Q^T M$.  We are interested in the range of $M$, let's call this $MX$.  $Q$ has orthonormal columns so $Q^TQ = I$ (but $QQ^T$ isn't $I$, since $Q$ is rectangular)\n",
    "\n",
    "$$ QR = MX $$\n",
    "$$ QQ^TQR = QQ^TMX $$\n",
    "$$ QR = QQ^TMX $$\n",
    "so...\n",
    "$$ MX = QQ^TMX $$\n",
    "\n",
    "If $X$ is the identity, we'd be done (but then $X$ would be too big, and we wouldn't get the speed up we're looking for).  In our problem, $X$ is just a small random matrix.  The Johnson-Lindenstrauss Lemma provides some justification of why this works."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The QR Decomposition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be learning about the QR decomposition **in depth** later on.  For now, you just need to know that $A = QR$, where $Q$ consists of orthonormal columns, and $R$ is upper triangular.  Trefethen says that the QR decomposition is the most important idea in numerical linear algebra!  We will definitely be returning to it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How should we choose $r$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose our matrix has 100 columns, and we want 5 columns in U and V. To be safe, we should project our matrix onto an orthogonal basis with a few more rows and columns than 5 (let's use 15).  At the end, we will just grab the first 5 columns of U and V\n",
    "\n",
    "So even although our projection was only approximate, by making it a bit bigger than we need, we can make up for the loss of accuracy (since we're only taking a subset later). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
